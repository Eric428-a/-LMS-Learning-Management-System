{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhIgTLBW06lEs2TWkViT25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eric428-a/-LMS-Learning-Management-System/blob/master/2_3_4_Hand_Gesture_Recognition_Starter_Kit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setting Up Your Environment"
      ],
      "metadata": {
        "id": "g0U-6pRGpN7_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrQXxj7kkjCg",
        "outputId": "3bdd40f3-d4e1-469b-ea70-56d7115a1559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas matplotlib tensorflow keras scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GFmUe07led_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-4h-wIZlee_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Downloading the Dataset"
      ],
      "metadata": {
        "id": "OaH8uaohpY69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the Sign Language MNIST dataset from Kaggle: [Sign Language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist). Unzip the files and place them in a directory named `data` in your project folder.\n"
      ],
      "metadata": {
        "id": "5Z3ht9mFpX4E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQXxBU2CpX49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rclULJXKpX9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Loading and Preprocessing the Data"
      ],
      "metadata": {
        "id": "j-c62_I5pl1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary working libraries and load the dataset:"
      ],
      "metadata": {
        "id": "DKUqMPm3pX-J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import NumPy library as np\n",
        "# NumPy is a fundamental package for scientific computing with Python, providing support for arrays, matrices, and mathematical functions.\n"
      ],
      "metadata": {
        "id": "WZPvN6pdlei4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "IjMf7a0Zl-TA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "it8IrG5XqGS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas library as pd\n",
        "# Pandas is a powerful data manipulation and analysis library for Python, providing DataFrame data structures and various data manipulation tools.\n"
      ],
      "metadata": {
        "id": "c5MUZ9MUqGT6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "btanVdk5qGYI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jczWGVguqGZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function from sklearn.model_selection module\n",
        "# train_test_split is a function used to split datasets into random train and test subsets, which is essential for model evaluation and validation.\n"
      ],
      "metadata": {
        "id": "jkh3lgvdqGd8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZQjsAHYel-T0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YnLuTM9BqVlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import to_categorical function from tensorflow.keras.utils module\n",
        "# to_categorical is a function used to convert class vectors (integers) to binary class matrices (one-hot encoded vectors), necessary for categorical classification tasks.\n"
      ],
      "metadata": {
        "id": "ij7r9wX3qVmZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "3vlFvWUjqVqR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rk4R3SlUrNrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9benooYrNse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using pandas read_csv function\n",
        "# pd.read_csv is a pandas function used to read data from a CSV file into a DataFrame, allowing easy manipulation and analysis of tabular data.\n"
      ],
      "metadata": {
        "id": "-ENBNhAVqVwH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('sign_mnist_train.csv')"
      ],
      "metadata": {
        "id": "JDqorRKXl-Yt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('sign_mnist_test.csv')"
      ],
      "metadata": {
        "id": "bZaslPmIrG9h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AiH4lTdirS3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l3KszRqVrS4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The training and test datasets are now loaded into DataFrame objects: train_df and test_df, respectively.\n",
        "# These DataFrames contain the data in a tabular format, with rows representing samples and columns representing features.\n",
        "# Each row corresponds to an image, with pixel values as features, and the 'label' column representing the class label for each image."
      ],
      "metadata": {
        "id": "uWHNDlTZl-Zl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PM4jTpvGmzyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vu-Japc4mzzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Handling Missing Values\n",
        "# Remove any rows with missing values from the training dataset"
      ],
      "metadata": {
        "id": "Vg0DHgHzrg0p"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "4tiuOue4rg10"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z7z0H0i6rq3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows with missing values from the test dataset"
      ],
      "metadata": {
        "id": "S3N6aqsOrg6N"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "0o-Gl77Brg7S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRsiU9Ofrg_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values again to ensure they've been handled"
      ],
      "metadata": {
        "id": "hgOTgVoYrhAl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_train = train_df.isnull().sum()"
      ],
      "metadata": {
        "id": "UviCMeN7rzD_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in the training dataset after handling:\", missing_values_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQT0ltvQrzFP",
        "outputId": "ec539ad1-308b-4cd2-b469-73123ad2c3dc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in the training dataset after handling: label       0\n",
            "pixel1      0\n",
            "pixel2      0\n",
            "pixel3      0\n",
            "pixel4      0\n",
            "           ..\n",
            "pixel780    0\n",
            "pixel781    0\n",
            "pixel782    0\n",
            "pixel783    0\n",
            "pixel784    0\n",
            "Length: 785, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qqDtWCrHrzIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMCRvPgyrzJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_test = test_df.isnull().sum()"
      ],
      "metadata": {
        "id": "Q09wHqq9rzO2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in the test dataset after handling:\", missing_values_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxfCnFLzr8dZ",
        "outputId": "fb4b763e-200d-4ebd-d8d0-b17108a594bb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in the test dataset after handling: label       0\n",
            "pixel1      0\n",
            "pixel2      0\n",
            "pixel3      0\n",
            "pixel4      0\n",
            "           ..\n",
            "pixel780    0\n",
            "pixel781    0\n",
            "pixel782    0\n",
            "pixel783    0\n",
            "pixel784    0\n",
            "Length: 785, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_j_bd6Fr8eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_bK4qZer8iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next step: Separate features and labels\n",
        "# Extract features (pixels) and labels from the datasets"
      ],
      "metadata": {
        "id": "UkBv1f7wr8jh"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop('label', axis=1).values  # Features: pixel values of images"
      ],
      "metadata": {
        "id": "JsdiLkXjrhFj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_df['label'].values  # Labels: corresponding hand gesture classes"
      ],
      "metadata": {
        "id": "jE8JjSaIsK_e"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_df.drop('label', axis=1).values  # Features of the test dataset"
      ],
      "metadata": {
        "id": "f8xnGii_sLAu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = test_df['label'].values  # Labels of the test dataset"
      ],
      "metadata": {
        "id": "sKvaT30NsLEr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hxAhX4o3sLF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QoS0g_fbsLJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next Step: Normalize the Data\n",
        "# Normalize pixel values to ensure they fall between 0 and 1"
      ],
      "metadata": {
        "id": "WU4-CutmsLKW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255.0  # Normalize training data"
      ],
      "metadata": {
        "id": "Ioo_iiscsLNf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test / 255.0  # Normalize test data"
      ],
      "metadata": {
        "id": "wxUz-BDcsLOt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "betJMJqesdmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oyFrIi2Gsq-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next Step: Reshape for CNN Input\n",
        "# Reshape data for compatibility with Convolutional Neural Networks (CNNs)\n",
        "# Convert 1D pixel arrays to 2D images (28x28 pixels with a single channel)"
      ],
      "metadata": {
        "id": "nJmzObZLsdnh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 28, 28, 1)  # Reshape training data"
      ],
      "metadata": {
        "id": "-TsZVu1Ksdq4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test.reshape(-1, 28, 28, 1)  # Reshape test data"
      ],
      "metadata": {
        "id": "ieF9t4fnsdsv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cnqtJt8sdvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7qj-s53sdw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next Step: One-Hot Encode the Labels\n",
        "# Convert labels to one-hot encoded format for categorical classification\n",
        "# Each label is represented as a binary vector indicating the class (e.g., [0, 0, 1, 0, 0] for class 3)"
      ],
      "metadata": {
        "id": "zBptTHp-sd0W"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)  # One-hot encode training labels"
      ],
      "metadata": {
        "id": "OUJ2G_YOsshj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = to_categorical(y_test)  # One-hot encode test labels"
      ],
      "metadata": {
        "id": "cgfqlDFFssi6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Tndko1yssmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset shapes after preprocessing"
      ],
      "metadata": {
        "id": "4_GBOm4bssoD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training dataset shape:\", X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWfbzngFsssd",
        "outputId": "0e60dbd2-06ba-46aa-d527-f79bcb16a088"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset shape: (27455, 28, 28, 1) (27455, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D8W3O45TtAU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test dataset shape:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNLlYGwKsd1q",
        "outputId": "ac8ea3d0-fd5a-4c9e-f8ce-21aa57a6d2c9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset shape: (7172, 28, 28, 1) (7172, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8-FsnJB8sd5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZufnGG_StMCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Building the CNN Model"
      ],
      "metadata": {
        "id": "VIVHM6uCtXfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules from TensorFlow Keras\n",
        "# TensorFlow Keras is a high-level neural networks API provided by TensorFlow, a popular deep learning framework.\n",
        "# Sequential model is used to create a linear stack of layers in the neural network."
      ],
      "metadata": {
        "id": "C6F_To4vtMD9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "nYgMmsFPtMG8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "57bgNghItMIZ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWA505EYtMLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model architecture using Sequential API\n",
        "# Sequential model allows us to create a linear stack of layers.\n",
        "# The layers are added one by one in the order they are passed to the Sequential constructor."
      ],
      "metadata": {
        "id": "yKh7PuFytoUX"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # Convolutional layer with 64 filters, kernel size of (3,3), ReLU activation function, and input shape (28,28,1)\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "    # MaxPooling layer with pool size of (2,2)\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolutional layer with 128 filters, kernel size of (3,3), and ReLU activation function\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "    # MaxPooling layer with pool size of (2,2)\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Flatten layer to flatten the input from 2D to 1D\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully connected Dense layer with 512 neurons and ReLU activation function\n",
        "    Dense(512, activation='relu'),\n",
        "\n",
        "    # Dropout layer to prevent overfitting by randomly setting a fraction of input units to zero during training\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Output layer with 25 neurons and softmax activation function\n",
        "    Dense(25, activation='softmax')  # 25 classes for the ASL alphabet\n",
        "])"
      ],
      "metadata": {
        "id": "dQx8nV5BtoV4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kcjpMu0toZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qACnuor0toaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "# Compiling the model configures the learning process with an optimizer, loss function, and evaluation metrics."
      ],
      "metadata": {
        "id": "a0Cy3a9ktMMw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wl5AMUgntMRG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ku---Db7sd6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model is now defined and compiled, ready for training with the specified optimizer, loss function, and metrics."
      ],
      "metadata": {
        "id": "QEuTrFr_uCFV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZhvWFQVuCJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "coHBYa3muCLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Training the Model"
      ],
      "metadata": {
        "id": "QVz_wIFuuNnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the training data\n",
        "# The fit() function is used to train the model. It takes the input data (X_train), target data (y_train),\n",
        "# number of epochs (how many times the entire training dataset will be passed forward and backward through the model),\n",
        "# validation data (X_test, y_test) to evaluate the model after each epoch, and batch size (number of samples per gradient update).\n",
        "# During training, the model learns to minimize the defined loss function (categorical_crossentropy) using the specified optimizer (adam).\n"
      ],
      "metadata": {
        "id": "7N5BshvpuCMY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKwVEYt-uCOL",
        "outputId": "d76eb557-b2e5-4d87-ae3b-9a3df4d0db22"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "215/215 [==============================] - 65s 300ms/step - loss: 1.4921 - accuracy: 0.5505 - val_loss: 0.5458 - val_accuracy: 0.8175\n",
            "Epoch 2/20\n",
            "215/215 [==============================] - 64s 300ms/step - loss: 0.2437 - accuracy: 0.9258 - val_loss: 0.3013 - val_accuracy: 0.9048\n",
            "Epoch 3/20\n",
            "215/215 [==============================] - 66s 309ms/step - loss: 0.0759 - accuracy: 0.9799 - val_loss: 0.2343 - val_accuracy: 0.9244\n",
            "Epoch 4/20\n",
            "215/215 [==============================] - 63s 291ms/step - loss: 0.0377 - accuracy: 0.9917 - val_loss: 0.2178 - val_accuracy: 0.9336\n",
            "Epoch 5/20\n",
            "215/215 [==============================] - 64s 300ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.2536 - val_accuracy: 0.9339\n",
            "Epoch 6/20\n",
            "215/215 [==============================] - 64s 298ms/step - loss: 0.0179 - accuracy: 0.9955 - val_loss: 0.2592 - val_accuracy: 0.9325\n",
            "Epoch 7/20\n",
            "215/215 [==============================] - 64s 300ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.2832 - val_accuracy: 0.9276\n",
            "Epoch 8/20\n",
            "215/215 [==============================] - 63s 292ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.3125 - val_accuracy: 0.9292\n",
            "Epoch 9/20\n",
            "215/215 [==============================] - 64s 299ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.2360 - val_accuracy: 0.9382\n",
            "Epoch 10/20\n",
            "215/215 [==============================] - 64s 298ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.2723 - val_accuracy: 0.9304\n",
            "Epoch 11/20\n",
            "215/215 [==============================] - 64s 299ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.2051 - val_accuracy: 0.9456\n",
            "Epoch 12/20\n",
            "215/215 [==============================] - 63s 292ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.2830 - val_accuracy: 0.9370\n",
            "Epoch 13/20\n",
            "215/215 [==============================] - 66s 307ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.2999 - val_accuracy: 0.9339\n",
            "Epoch 14/20\n",
            "215/215 [==============================] - 64s 296ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.2914 - val_accuracy: 0.9356\n",
            "Epoch 15/20\n",
            "215/215 [==============================] - 62s 289ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.2719 - val_accuracy: 0.9426\n",
            "Epoch 16/20\n",
            "215/215 [==============================] - 66s 306ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.2897 - val_accuracy: 0.9451\n",
            "Epoch 17/20\n",
            "215/215 [==============================] - 64s 298ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.2895 - val_accuracy: 0.9349\n",
            "Epoch 18/20\n",
            "215/215 [==============================] - 64s 297ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.2561 - val_accuracy: 0.9405\n",
            "Epoch 19/20\n",
            "215/215 [==============================] - 64s 299ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.2448 - val_accuracy: 0.9467\n",
            "Epoch 20/20\n",
            "215/215 [==============================] - 65s 304ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.2678 - val_accuracy: 0.9428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqesdiF8un2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lTaUU_1SuoBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, the model's performance is evaluated on the test set."
      ],
      "metadata": {
        "id": "tNWYjejAuoDD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOqIj3O2uokZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rT9zHzN2uol0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Evaluating the Model"
      ],
      "metadata": {
        "id": "kS0JNTa4uua6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the trained model on the test set\n",
        "# The evaluate() function computes the loss value and accuracy of the model on the test data.\n",
        "# It takes the input test data (X_test) and corresponding true labels (y_test)."
      ],
      "metadata": {
        "id": "JdJ4_wstuop4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv42lWY4uorc",
        "outputId": "e2ff5c1f-4214-4cbf-e246-671c52069066"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 4s 19ms/step - loss: 0.2678 - accuracy: 0.9428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCyqmBQcupB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the test accuracy"
      ],
      "metadata": {
        "id": "WBtFVwAFupEM"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwlbXTZTu-ru",
        "outputId": "8b5e80dc-8fa9-4064-9f0d-9b7b8e6ba5b9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9428332448005676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTX2jCeDu-tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VFBTFcfJu-we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Making Predictions"
      ],
      "metadata": {
        "id": "OG5DTLR3vFTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on new data\n",
        "# The predict() function generates output predictions for the input samples.\n",
        "# Here, we make predictions on the first 5 images in the test set (X_test[:5])."
      ],
      "metadata": {
        "id": "gKGdL66Pu-yB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m9uR2Fmu-1j",
        "outputId": "e654481b-3411-4bc4-f93b-f163784dda77"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1ekh8c-u-3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the predicted labels for the first 5 images\n",
        "# argmax() function returns the indices of the maximum values along an axis.\n",
        "# In this case, it returns the indices corresponding to the classes with the highest predicted probability."
      ],
      "metadata": {
        "id": "T6YtyP-fvMXT"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.argmax(predictions, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFa83uSvvMY_",
        "outputId": "97ae3672-44fb-4840-fa6d-e2ef6eee4d9d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 6  5 10  0  3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADE8eSufvMq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}